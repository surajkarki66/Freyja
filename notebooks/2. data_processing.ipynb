{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0818e8d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2eb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from string import punctuation\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86808d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/surajkarki/.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53d977",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f4558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Dataset/processed_dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f970d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>338</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>419</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>524</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>465</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0           0         1          1   \n",
       "1           1         2          1   \n",
       "2           2         3          1   \n",
       "3           3         4          1   \n",
       "4           4         5          1   \n",
       "\n",
       "                                               essay  word_count  final_score  \n",
       "0  Dear local newspaper, I think effects computer...         338            6  \n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...         419            7  \n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...         279            5  \n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...         524            8  \n",
       "4  Dear @LOCATION1, I know having computers has a...         465            6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9efda602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbec73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>338</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>419</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>524</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>465</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   word_count  final_score  \n",
       "0         338            6  \n",
       "1         419            7  \n",
       "2         279            5  \n",
       "3         524            8  \n",
       "4         465            6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb026387",
   "metadata": {},
   "source": [
    "## Essay Processing\n",
    "It is divided into 5 steps:\n",
    "1. Language Correction\n",
    "2. Sentence tokenization, Sentence count and length, Word tokenization\n",
    "3. Word token classification (punctuation, stop words and anonymized entities, pos, ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af408f",
   "metadata": {},
   "source": [
    "### 1. Language Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080f5d1",
   "metadata": {},
   "source": [
    "Student's essays posses lots of grammar and spelling errors. Parts-of-speech (POS) and named-entity-recognition (NER) is hampered in part by the lack of consistent spelling and punctuation. Therefore, the essays will be corrected using languagetool and the nlp parsing will be performed with Spacy on the corrected essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb1df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: language-tool-python in /home/surajkarki/anaconda3/lib/python3.11/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: requests in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from language-tool-python) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from language-tool-python) (4.65.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests->language-tool-python) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests->language-tool-python) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests->language-tool-python) (1.26.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/surajkarki/anaconda3/lib/python3.11/site-packages (from requests->language-tool-python) (2023.7.22)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install language-tool-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902a1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "876dfcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 5.7: 100%|██████████████████████████████████████████████████████████████████████████| 225M/225M [00:29<00:00, 7.73MB/s]\n",
      "Unzipping /tmp/tmpat77pdnd.zip to /home/surajkarki/.cache/language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-5.7.zip to /home/surajkarki/.cache/language_tool_python.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 0:24:41.084574\n"
     ]
    }
   ],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "t0 = datetime.now()\n",
    "df['matches'] = df['essay'].apply(lambda txt: tool.check(txt))\n",
    "df['corrections'] = df.apply(lambda l: len(l['matches']), axis=1)\n",
    "df['corrected'] = df.apply(lambda l: language_tool_python.utils.correct(l['essay'], l['matches']), axis=1)\n",
    "\n",
    "\n",
    "t1 = datetime.now()\n",
    "print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700336e",
   "metadata": {},
   "source": [
    "Let's see a very special example of poor writing skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5142be29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "I aegre waf the evansmant ov tnachnolage. The evansmant ov tnachnolige is being to halp fined a kohar froi alnsas. Tnanchnolage waf ont ot we wod not go to the moon. Tnachnologe evans as we maech at. The people are in tnacholege to the frchr fror the good ov live. Famas invanyor ues tnacholage leki lena orde dvanse and his fling mashine. Tnachologe is the grat\n",
      "Corrected with languagetool\n",
      "I Segre weigh the evanescent of tnachnolage. The evanescent of tnachnolige is being to half fined a Zohar from Kansas. Tnanchnolage weigh on tot we won not go to the moon. Technology Evans as we match at. The people are in tnacholege to the arch for the good of live. FAMAS inventor UES anchorage Levi Lena order dance and his fling machine. Tnachologe is the great\n"
     ]
    }
   ],
   "source": [
    "print('Original:')\n",
    "print(df.essay[18])\n",
    "print('Corrected with languagetool')\n",
    "print(df.corrected[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed23bd",
   "metadata": {},
   "source": [
    "### 2. Sentence tokenization, Sentence count and length, Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a06786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 0:05:34.070084\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "ner = []\n",
    "\n",
    "stop_words = set(STOP_WORDS)\n",
    "stop_words.update(punctuation)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "t0 = datetime.now()\n",
    "\n",
    "# suppress numpy warnings\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "for essay in nlp.pipe(df['corrected'], batch_size=100):\n",
    "    if essay.is_parsed:\n",
    "        tokens.append([e.text for e in essay])\n",
    "        sents.append([sent.text.strip() for sent in essay.sents])\n",
    "        pos.append([e.pos_ for e in essay])\n",
    "        ner.append([e.text for e in essay.ents])\n",
    "        lemma.append([n.lemma_ for n in essay])\n",
    "    else:\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        sents.append(None)\n",
    "        ner.append(None)\n",
    "\n",
    "df['tokens'] = tokens\n",
    "df['lemma'] = lemma\n",
    "df['pos'] = pos\n",
    "df['sents'] = sents\n",
    "df['ner'] = ner\n",
    "\n",
    "t1 = datetime.now()\n",
    "print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e4849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>final_score</th>\n",
       "      <th>matches</th>\n",
       "      <th>corrections</th>\n",
       "      <th>corrected</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>sents</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>338</td>\n",
       "      <td>6</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, ,, I, think, effects,...</td>\n",
       "      <td>[dear, local, newspaper, ,, I, think, effect, ...</td>\n",
       "      <td>[ADJ, ADJ, NOUN, PUNCT, PRON, VERB, NOUN, NOUN...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>[Facebook, MySpace]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>419</td>\n",
       "      <td>7</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>25</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>[Dear, @CAPS1, @CAPS2, ,, I, believe, that, us...</td>\n",
       "      <td>[Dear, @CAPS1, @CAPS2, ,, I, believe, that, us...</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PUNCT, PRON, VERB, SCONJ...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>[Facebook and MySpace, millions, one, MySpace,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>17</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>[Dear, ,, @CAPS1, @CAPS2, @CAPS3, More, and, m...</td>\n",
       "      <td>[dear, ,, @CAPS1, @CAPS2, @CAPS3, More, and, m...</td>\n",
       "      <td>[ADJ, PUNCT, PROPN, PROPN, PROPN, ADJ, CCONJ, ...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>[today, one, a thousand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>524</td>\n",
       "      <td>8</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>29</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>[Dear, Local, Newspaper, ,, @CAPS1, I, have, f...</td>\n",
       "      <td>[Dear, Local, Newspaper, ,, @CAPS1, I, have, f...</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PUNCT, PROPN, PRON, AUX,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>[Dear Local Newspaper, @PERSON1, A+, @CAPS7, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>465</td>\n",
       "      <td>6</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>17</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>[Dear, @LOCATION1, ,, I, know, having, compute...</td>\n",
       "      <td>[dear, @LOCATION1, ,, I, know, have, computer,...</td>\n",
       "      <td>[ADJ, PROPN, PUNCT, PRON, VERB, VERB, NOUN, VE...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>[First, one, Secondly, one, only one]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0           0         1          1   \n",
       "1           1         2          1   \n",
       "2           2         3          1   \n",
       "3           3         4          1   \n",
       "4           4         5          1   \n",
       "\n",
       "                                               essay  word_count  final_score  \\\n",
       "0  Dear local newspaper, I think effects computer...         338            6   \n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...         419            7   \n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...         279            5   \n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...         524            8   \n",
       "4  Dear @LOCATION1, I know having computers has a...         465            6   \n",
       "\n",
       "                                             matches  corrections  \\\n",
       "0  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           16   \n",
       "1  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           25   \n",
       "2  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           17   \n",
       "3  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           29   \n",
       "4  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           17   \n",
       "\n",
       "                                           corrected  \\\n",
       "0  Dear local newspaper, I think effects computer...   \n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Dear, local, newspaper, ,, I, think, effects,...   \n",
       "1  [Dear, @CAPS1, @CAPS2, ,, I, believe, that, us...   \n",
       "2  [Dear, ,, @CAPS1, @CAPS2, @CAPS3, More, and, m...   \n",
       "3  [Dear, Local, Newspaper, ,, @CAPS1, I, have, f...   \n",
       "4  [Dear, @LOCATION1, ,, I, know, having, compute...   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  [dear, local, newspaper, ,, I, think, effect, ...   \n",
       "1  [Dear, @CAPS1, @CAPS2, ,, I, believe, that, us...   \n",
       "2  [dear, ,, @CAPS1, @CAPS2, @CAPS3, More, and, m...   \n",
       "3  [Dear, Local, Newspaper, ,, @CAPS1, I, have, f...   \n",
       "4  [dear, @LOCATION1, ,, I, know, have, computer,...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [ADJ, ADJ, NOUN, PUNCT, PRON, VERB, NOUN, NOUN...   \n",
       "1  [PROPN, PROPN, PROPN, PUNCT, PRON, VERB, SCONJ...   \n",
       "2  [ADJ, PUNCT, PROPN, PROPN, PROPN, ADJ, CCONJ, ...   \n",
       "3  [PROPN, PROPN, PROPN, PUNCT, PROPN, PRON, AUX,...   \n",
       "4  [ADJ, PROPN, PUNCT, PRON, VERB, VERB, NOUN, VE...   \n",
       "\n",
       "                                               sents  \\\n",
       "0  [Dear local newspaper, I think effects compute...   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...   \n",
       "4  [Dear @LOCATION1, I know having computers has ...   \n",
       "\n",
       "                                                 ner  \n",
       "0                                [Facebook, MySpace]  \n",
       "1  [Facebook and MySpace, millions, one, MySpace,...  \n",
       "2                           [today, one, a thousand]  \n",
       "3  [Dear Local Newspaper, @PERSON1, A+, @CAPS7, N...  \n",
       "4              [First, one, Secondly, one, only one]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae98b7",
   "metadata": {},
   "source": [
    "## Count various features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b7fa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 0:00:03.164669\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "df['token_count'] = df.apply(lambda x: len(x['tokens']), axis=1)\n",
    "df['unique_token_count'] = df.apply(lambda x: len(set(x['tokens'])), axis=1)\n",
    "df['nostop_count'] = df.apply(lambda x: len([token for token in x['tokens'] if token not in stop_words]), axis=1)\n",
    "df['sent_count'] = df.apply(lambda x: len(x['sents']), axis=1)\n",
    "df['ner_count'] = df.apply(lambda x: len(x['ner']), axis=1)\n",
    "df['comma'] = df.apply(lambda x: x['corrected'].count(','), axis=1)\n",
    "df['question'] = df.apply(lambda x: x['corrected'].count('?'), axis=1)\n",
    "df['exclamation'] = df.apply(lambda x: x['corrected'].count('!'), axis=1)\n",
    "df['quotation'] = df.apply(lambda x: x['corrected'].count('\"') + x['corrected'].count(\"'\"), axis=1)\n",
    "df['organization'] = df.apply(lambda x: x['corrected'].count(r'@ORGANIZATION'), axis=1)\n",
    "df['caps'] = df.apply(lambda x: x['corrected'].count(r'@CAPS'), axis=1)\n",
    "df['person'] = df.apply(lambda x: x['corrected'].count(r'@PERSON'), axis=1)\n",
    "df['location'] = df.apply(lambda x: x['corrected'].count(r'@LOCATION'), axis=1)\n",
    "df['money'] = df.apply(lambda x: x['corrected'].count(r'@MONEY'), axis=1)\n",
    "df['time'] = df.apply(lambda x: x['corrected'].count(r'@TIME'), axis=1)\n",
    "df['date'] = df.apply(lambda x: x['corrected'].count(r'@DATE'), axis=1)\n",
    "df['percent'] = df.apply(lambda x: x['corrected'].count(r'@PERCENT'), axis=1)\n",
    "df['noun'] = df.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
    "df['adj'] = df.apply(lambda x: x['pos'].count('ADJ'), axis=1)\n",
    "df['pron'] = df.apply(lambda x: x['pos'].count('PRON'), axis=1)\n",
    "df['verb'] = df.apply(lambda x: x['pos'].count('VERB'), axis=1)\n",
    "df['noun'] = df.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
    "df['cconj'] = df.apply(lambda x: x['pos'].count('CCONJ'), axis=1)\n",
    "df['adv'] = df.apply(lambda x: x['pos'].count('ADV'), axis=1)\n",
    "df['det'] = df.apply(lambda x: x['pos'].count('DET'), axis=1)\n",
    "df['propn'] = df.apply(lambda x: x['pos'].count('PROPN'), axis=1)\n",
    "df['num'] = df.apply(lambda x: x['pos'].count('NUM'), axis=1)\n",
    "df['part'] = df.apply(lambda x: x['pos'].count('PART'), axis=1)\n",
    "df['intj'] = df.apply(lambda x: x['pos'].count('INTJ'), axis=1)\n",
    "\n",
    "t1 = datetime.now()\n",
    "\n",
    "print('Processing time: {}'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3c2cca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>final_score</th>\n",
       "      <th>matches</th>\n",
       "      <th>corrections</th>\n",
       "      <th>corrected</th>\n",
       "      <th>tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>adj</th>\n",
       "      <th>pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>cconj</th>\n",
       "      <th>adv</th>\n",
       "      <th>det</th>\n",
       "      <th>propn</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>intj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>338</td>\n",
       "      <td>6</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, ,, I, think, effects,...</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>419</td>\n",
       "      <td>7</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>25</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>[Dear, @CAPS1, @CAPS2, ,, I, believe, that, us...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>17</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>[Dear, ,, @CAPS1, @CAPS2, @CAPS3, More, and, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>524</td>\n",
       "      <td>8</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>29</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>[Dear, Local, Newspaper, ,, @CAPS1, I, have, f...</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>465</td>\n",
       "      <td>6</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>17</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>[Dear, @LOCATION1, ,, I, know, having, compute...</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0           0         1          1   \n",
       "1           1         2          1   \n",
       "2           2         3          1   \n",
       "3           3         4          1   \n",
       "4           4         5          1   \n",
       "\n",
       "                                               essay  word_count  final_score  \\\n",
       "0  Dear local newspaper, I think effects computer...         338            6   \n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...         419            7   \n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...         279            5   \n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...         524            8   \n",
       "4  Dear @LOCATION1, I know having computers has a...         465            6   \n",
       "\n",
       "                                             matches  corrections  \\\n",
       "0  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           16   \n",
       "1  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           25   \n",
       "2  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           17   \n",
       "3  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           29   \n",
       "4  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...           17   \n",
       "\n",
       "                                           corrected  \\\n",
       "0  Dear local newspaper, I think effects computer...   \n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "                                              tokens  ... adj pron verb cconj  \\\n",
       "0  [Dear, local, newspaper, ,, I, think, effects,...  ...  17   48   51    14   \n",
       "1  [Dear, @CAPS1, @CAPS2, ,, I, believe, that, us...  ...  20   51   70    18   \n",
       "2  [Dear, ,, @CAPS1, @CAPS2, @CAPS3, More, and, m...  ...  19   27   40    16   \n",
       "3  [Dear, Local, Newspaper, ,, @CAPS1, I, have, f...  ...  42   33   73    17   \n",
       "4  [Dear, @LOCATION1, ,, I, know, having, compute...  ...  28   41   61    16   \n",
       "\n",
       "   adv  det  propn  num  part  intj  \n",
       "0   15   21      6    0    16     2  \n",
       "1   18   30     12    5    10     0  \n",
       "2   11   25      6    3    10     0  \n",
       "3   20   42     37    0    23     0  \n",
       "4   33   49      3    4    20     0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3025b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./Dataset/processed_dataset_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8effcca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
